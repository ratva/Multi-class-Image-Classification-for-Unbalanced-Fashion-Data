{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# General functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sci-kit learn\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, PredefinedSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.pipeline\n",
    "import sklearn.metrics\n",
    "# import sklearn.linear_model\n",
    "# import sklearn.model_selection as skms\n",
    "# import sklearn.feature_selection\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our custom functions\n",
    "from load_data import load_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data:\n",
    "\n",
    "x data is an array of N*784 pixels (N = 2102 for tr, 600 for va)\n",
    "\n",
    "y is a dataframe of index, class_name and class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr_df = load_data('x_train.csv', 'y_train.csv')\n",
    "x_va, y_va_df = load_data('x_valid.csv', 'y_valid.csv')\n",
    "x_te = load_data('x_test.csv', 'y_valid.csv')[0]\n",
    "\n",
    "\n",
    "for label, arr in [('train', x_tr), ('valid', x_va)]:\n",
    "    print(\"Contents of %s_x.csv: arr of shape %s\" % (\n",
    "        label, str(arr.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a random image from the validation data for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prng = np.random.RandomState(0)\n",
    "prng = np.random.RandomState()\n",
    "N = 3 # num examples of each class to show\n",
    "fig, axgrid = plt.subplots(N, 6, figsize=(6*3, N*2.5))\n",
    "\n",
    "for ll, label in enumerate(['dress', 'pullover', 'top', 'trouser', 'sandal', 'sneaker']):\n",
    "    match_df = y_va_df.query(\"class_name == '%s'\" % label)\n",
    "    match_ids_N = prng.choice(match_df.index, size=N)        \n",
    "    for ii, row_id in enumerate(match_ids_N):\n",
    "        ax = axgrid[ii, ll]\n",
    "        x_SS = x_va[row_id].reshape((28,28))\n",
    "        ax.imshow(x_SS, vmin=0, vmax=255, cmap='gray')\n",
    "        ax.set_xticks([]); ax.set_yticks([]);\n",
    "        if ii == 0:\n",
    "            ax.set_title(label, fontsize=16)\n",
    "plt.subplots_adjust(left=0.01, right=0.99, wspace=.2, hspace=.01)\n",
    "plt.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_class_dist = y_tr_df['class_name'].value_counts()\n",
    "val_class_dist = y_va_df['class_name'].value_counts()\n",
    "\n",
    "print('Training class distribution:\\n' + str(tr_class_dist))\n",
    "print('Validation class distribution:\\n' + str(val_class_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is heavily skewed with data from sandals and trainers, with only one training image for 2 classes. A challenge will be gaining a balanced weighting for each of the classes such that the dominant classes aren't always favoured by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run search with predefined split s.t. validation set is used for hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation datasets\n",
    "x_all = np.vstack((x_tr,x_va))\n",
    "y_all_df = pd.concat([y_tr_df,y_va_df])\n",
    "\n",
    "print(\"Training X shape: %s\\nValidation X shape: %s\\nCombined X shape: %s\\n\" % (x_tr.shape, x_va.shape, x_all.shape))\n",
    "print(\"Training Y shape: %s\\nValidation Y shape: %s\\nCombined Y shape: %s\\n\" % (y_tr_df.shape, y_va_df.shape, y_all_df.shape))\n",
    "\n",
    "valid_indicators = np.hstack([\n",
    "    -1 * np.ones(y_tr_df.shape[0]), # -1 means never include this example in any test split\n",
    "    0  * np.ones(y_va_df.shape[0]), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])\n",
    "\n",
    "# Define custom splitter to use only the validation dataset for hyperparameter selection\n",
    "print(\"Splitter dimensions: %i\" % (valid_indicators.shape[0]))\n",
    "my_splitter = PredefinedSplit(valid_indicators)\n",
    "\n",
    "display(y_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search\n",
    "Load previous model or run new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Older run with some unnecesary parameters.\n",
    "flag = 'stop'\n",
    "filename = '1B_rand_search_400.sav'\n",
    "\n",
    "if os.path.isfile(\"./\" + filename) and flag != 'run':\n",
    "    rand_400_1b_model = pickle.load(open(filename, 'rb'))\n",
    "else:\n",
    "    param_dist = dict(activation=['relu', 'logistic', 'identity', 'tanh'], learning_rate_init=np.logspace(-5, 5, 100), learning_rate = ['constant','adaptive'], hidden_layer_sizes=[(10,),(20,),(50,),(100,),(200,),(500,)])\n",
    "\n",
    "    rand_400_1b_model = sklearn.pipeline.Pipeline([\n",
    "        ('rand_search', RandomizedSearchCV(sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True), param_dist, scoring='balanced_accuracy', error_score='raise', random_state=0, return_train_score=True, n_iter=400, cv= my_splitter, n_jobs = -1, refit=False))\n",
    "    ])\n",
    "\n",
    "    # Fit on x_all as the custom splitter will divide this into tr and val\n",
    "    rand_400_1b_model.fit(x_all, y_all_df['class_name'])\n",
    "    pickle.dump(rand_400_1b_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed following parameters that don't apply to lbfgs:\n",
    "# batch size only for non-lbfgs. \n",
    "# Learning Rate = const, adaptive, etc... ONLY for sgd\n",
    "# learning_rate_init only used for sgd or adam\n",
    "# early_stopping, n_iter_no_change and validation_fraction only for sgd/adam.\n",
    "\n",
    "flag = 'stop'\n",
    "filename = '1B_rand_search_600.sav'\n",
    "\n",
    "if os.path.isfile(\"./\" + filename) and flag != 'run':\n",
    "    rand_600_1b_model = pickle.load(open(filename, 'rb'))\n",
    "else:\n",
    "    rand_param_dist = dict(hidden_layer_sizes=[(10,),(20,),(50,),(100,),(200,),(500,)], activation=('identity', 'logistic', 'tanh', 'relu'), max_iter = [1, 2, 3, 4, 5, 10, 20, 50, 100, 200, 300], alpha = np.logspace(-5,5,50))\n",
    "\n",
    "    rand_600_1b_model = sklearn.pipeline.Pipeline([\n",
    "        ('rand_search', RandomizedSearchCV(MLPClassifier(solver='lbfgs', shuffle=True, random_state=0), rand_param_dist, scoring='balanced_accuracy', error_score='raise', return_train_score=True, n_iter=600, cv= my_splitter, n_jobs = -1, refit= False, random_state=0))\n",
    "    ])\n",
    "\n",
    "    # Fit on x_all as the custom splitter will divide this into tr and val\n",
    "    rand_600_1b_model.fit(x_all, y_all_df['class_name'])\n",
    "    pickle.dump(rand_600_1b_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randRes = rand_600_1b_model['rand_search'].cv_results_\n",
    "bestIdx = rand_600_1b_model['rand_search'].best_index_ # idx 12, 16, 44 all scored the same\n",
    "\n",
    "bestIdxs = [12,16,44]\n",
    "bestParams = dict()\n",
    "# bestParams[0] = {k:v[bestIdxs[0]] for k,v in randRes.items()}\n",
    "# bestParams[1] = {k:v[bestIdxs[1]] for k,v in randRes.items()}\n",
    "# bestParams[2] = {k:v[bestIdxs[2]] for k,v in randRes.items()}\n",
    "bestParams[0] = {k:v[bestIdx] for k,v in randRes.items()}\n",
    "\n",
    "# display(bestParams)\n",
    "\n",
    "print(bestIdx)\n",
    "print(randRes['params'][bestIdx])\n",
    "print(randRes[\"rank_test_score\"][bestIdx])\n",
    "display(randRes[\"mean_test_score\"][bestIdx])\n",
    "print(bestParams[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the custom splitter, it's saying the following:\n",
    "\n",
    "best idx = 264\n",
    "best params = {'max_iter': 100, 'hidden_layer_sizes': (200,), 'alpha': 1456.3484775012444, 'activation': 'relu'}\n",
    "test score = 0.775\n",
    "\n",
    "However when we take those parameters and make a new model and fit it to training, it performs much worse on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestMLP1b = sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True, learning_rate_init=1e-05,learning_rate ='constant',hidden_layer_sizes=(500,),activation='identity')\n",
    "# bestMLP1b.fit(x_tr,y_tr_df[\"class_name\"])\n",
    "\n",
    "bestMLP1b = MLPClassifier(solver='lbfgs', shuffle=True, random_state=0, max_iter=100, hidden_layer_sizes=(200,), alpha=1456.3484775012444, activation='relu')\n",
    "\n",
    "bestMLP1b.fit(x_tr,y_tr_df[\"class_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = sklearn.metrics.balanced_accuracy_score(y_tr_df['class_name'], bestMLP1b.predict(x_tr))\n",
    "va_acc = sklearn.metrics.balanced_accuracy_score(y_va_df['class_name'], bestMLP1b.predict(x_va))\n",
    "print(\"Training balanced accuracy: %f\\nValidation balanced accuracy: %f\" % (tr_acc, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = sklearn.metrics.accuracy_score(y_tr_df['class_name'], bestMLP1b.predict(x_tr))\n",
    "va_acc = sklearn.metrics.accuracy_score(y_va_df['class_name'], bestMLP1b.predict(x_va))\n",
    "print(\"Training balanced accuracy: %f\\nValidation balanced accuracy: %f\" % (tr_acc, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = bestMLP1b.predict(x_tr)\n",
    "pred_va = bestMLP1b.predict(x_va)\n",
    "pred_te = bestMLP1b.predict(x_te)\n",
    "\n",
    "# Save output of prediction on test data to a file.\n",
    "np.savetxt('yhat_test.txt', pred_te, delimiter='\\n', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test data\n",
    "rows = 3\n",
    "cols = 7\n",
    "fig, axgrid = plt.subplots(rows, cols, layout=\"constrained\")\n",
    "\n",
    "for imageID in range(rows*cols):\n",
    "    ax = axgrid[np.unravel_index( imageID, (rows,cols))]\n",
    "    x_SS = x_te[imageID].reshape((28,28))\n",
    "    ax.imshow(x_SS, vmin=0, vmax=255, cmap='gray')\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    label = pred_te[imageID]\n",
    "    ax.set_title(label, fontsize=16)\n",
    "# plt.tight_layout();\n",
    "fig.suptitle(\"Sample of test data predictions by model 1B\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO refine search using gridsearchcv\n",
    "# param_dist = dict(activation=['relu', 'logistic', 'identity', 'tanh'], learning_rate_init=np.logspace(-5, 5, 100), learning_rate = ['constant','adaptive'], hidden_layer_sizes=[(20,),(50,),(100,),(200,),(500,)])\n",
    "\n",
    "# fashion_pipes = sklearn.pipeline.Pipeline([\n",
    "#     ('rand_search', GridSearchCV(sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True), param_dist, scoring='balanced_accuracy', error_score='raise', random_state=0, return_train_score=True, n_iter=100, cv= my_splitter, n_jobs = -1, refit=False))\n",
    "# ])\n",
    "\n",
    "# fashion_pipes.fit(x_all, y_all_df['class_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When refit is true we can use the best_estimator_ method, but this doesn't work with refit=false - here we need to manually run a fit on our training set.\n",
    "\n",
    "# best_est_1 = fashion_pipes['rand_search'].best_estimator_\n",
    "\n",
    "# pred_tr = best_est_1.predict(x_tr)\n",
    "# pred_va = best_est_1.predict(x_va)\n",
    "# pred_te = best_est_1.predict(x_te)\n",
    "\n",
    "# # Save output of prediction on test data to a file.\n",
    "# np.savetxt('yhat_test.txt', pred_te, delimiter='\\n', fmt='%s')\n",
    "# sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore for the time being - this was done with refit = true, which fits the final model from randomizedSearchCV onto the entire dataset (tr+val).\n",
    "\n",
    "![Balanced acc of 1.0 or tr and val](best_estimator_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat with data normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data - necessary\n",
    "x_tr_norm = x_tr /255\n",
    "x_va_norm = x_va /255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation datasets\n",
    "x_all_norm = np.vstack((x_tr_norm,x_va_norm))\n",
    "y_all_df = pd.concat([y_tr_df,y_va_df])\n",
    "\n",
    "print(\"Training X shape: %s\\nValidation X shape: %s\\nCombined X shape: %s\\n\" % (x_tr_norm.shape, x_va_norm.shape, x_all_norm.shape))\n",
    "print(\"Training Y shape: %s\\nValidation Y shape: %s\\nCombined Y shape: %s\\n\" % (y_tr_df.shape, y_va_df.shape, y_all_df.shape))\n",
    "\n",
    "valid_indicators = np.hstack([\n",
    "    -1 * np.ones(y_tr_df.shape[0]), # -1 means never include this example in any test split\n",
    "    0  * np.ones(y_va_df.shape[0]), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])\n",
    "\n",
    "# Define custom splitter to use only the validation dataset for hyperparameter selection\n",
    "print(\"Splitter dimensions: %i\" % (valid_indicators.shape[0]))\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 'stop'\n",
    "filename = '1Bnorm_rand_search_100.sav'\n",
    "\n",
    "if os.path.isfile(\"./\" + filename) and flag != 'run':\n",
    "    fashion_pipes_norm = pickle.load(open(filename, 'rb'))\n",
    "else:\n",
    "    param_dist = dict(activation=['relu', 'logistic', 'identity', 'tanh'], learning_rate_init=np.logspace(-5, 5, 100), learning_rate = ['constant','adaptive'], hidden_layer_sizes=[(20,),(50,),(100,),(200,),(500,)])\n",
    "\n",
    "    fashion_pipes_norm = sklearn.pipeline.Pipeline([\n",
    "        ('rand_search', RandomizedSearchCV(sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True), param_dist, scoring='balanced_accuracy', error_score='raise', random_state=0, return_train_score=True, n_iter=100, cv= my_splitter, n_jobs = -1, refit=False))\n",
    "    ])\n",
    "\n",
    "    fashion_pipes_norm.fit(x_all_norm, y_all_df['class_name'])\n",
    "    pickle.dump(fashion_pipes, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1D_initial_RanSearch.sav'\n",
    "print(\"./\" + filename)\n",
    "\n",
    "os.path.isfile(\"./\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the same procedure with normalized input data - same results and same accuracy found in this case.display\n",
    "\n",
    "gridRes = fashion_pipes['rand_search'].cv_results_\n",
    "\n",
    "display(gridRes)\n",
    "bestIdxNorm = fashion_pipes['rand_search'].best_index_ # idx 12, 16, 44 all scored the same\n",
    "\n",
    "bestIdxs = [12,16,44]\n",
    "bestParams = dict()\n",
    "bestParams[0] = {k:v[bestIdxs[0]] for k,v in gridRes.items()}\n",
    "bestParams[1] = {k:v[bestIdxs[1]] for k,v in gridRes.items()}\n",
    "bestParams[2] = {k:v[bestIdxs[2]] for k,v in gridRes.items()}\n",
    "\n",
    "display(bestParams)\n",
    "# print(gridRes[\"mean_test_score\"])\n",
    "# display(gridRes[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestMLP1bNorm = sklearn.neural_network.MLPClassifier( solver='lbfgs', random_state = 0, shuffle=True, early_stopping = True, learning_rate_init=1e-05,learning_rate ='constant',hidden_layer_sizes=(500,),activation='identity')\n",
    "bestMLP1bNorm.fit(x_tr_norm,y_tr_df[\"class_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = sklearn.metrics.balanced_accuracy_score(y_tr_df['class_name'], bestMLP1bNorm.predict(x_tr_norm))\n",
    "va_acc = sklearn.metrics.balanced_accuracy_score(y_va_df['class_name'], bestMLP1bNorm.predict(x_va_norm))\n",
    "print(\"Training balanced accuracy: %f\\nValidation balanced accuracy: %f\" % (tr_acc, va_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the validation accuracy seems to be lower on normalized data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
